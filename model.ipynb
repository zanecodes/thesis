{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "This file contains all the code necessary to build  and train the first stage pose estimation model as described in Figure 1b of [Hands Deep in Deep Learning](https://arxiv.org/pdf/1502.06807v2.pdf), but does not yet implement the hand pose prior constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_yaml, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import math\n",
    "import random\n",
    "import h5py\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "\n",
    "The default dataset location is the dataset/ subfolder of the project root.\n",
    "The [.hdf5](http://www.h5py.org/) file produced by [data.ipynb](data#Output-dataset) is placed in this directory after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET_DIR      = 'dataset'\n",
    "dataset          = h5py.File(path.join(DATASET_DIR, 'dataset.hdf5'))\n",
    "\n",
    "test_images      = dataset['image/test']\n",
    "test_labels      = dataset['label/test']\n",
    "test_centers     = dataset['center/test']\n",
    "\n",
    "train_images     = dataset['image/train']\n",
    "train_labels     = dataset['label/train']\n",
    "train_centers    = dataset['center/train']\n",
    "\n",
    "pca_eigenvectors = dataset['pca/eigenvectors'][:30]\n",
    "pca_mean         = dataset['pca/mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resize an image to the specified dimensions, scaling its label accordingly\n",
    "def resize(image, label, dimensions):\n",
    "    scale        = np.array(dimensions) / image.shape[:-1]\n",
    "    label[::3]  *= scale[1]\n",
    "    label[1::3] *= scale[0]\n",
    "    \n",
    "    # TODO: Try to implement or use OpenCV's INTER_AREA resize strategy?\n",
    "    image = scipy.misc.imresize(np.squeeze(image), dimensions, 'bilinear', mode='F')\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clip an image to the specified bounding box, translating its label accordingly\n",
    "# Bounding box should look like np.array([[x_1, y_1], [x_2, y_2]]), where\n",
    "# (x_1, y_1) are the coordinates of the lower left corner and \n",
    "# (x_2, y_2) are the coordinates of the upper right corner\n",
    "def clip(image, label, bounding_box):\n",
    "    label[::3]  -= bounding_box[0, 1]\n",
    "    label[1::3] -= bounding_box[0, 0]\n",
    "    \n",
    "    image_box = np.array([[0, 0], image.shape[:-1]], dtype='int')\n",
    "    \n",
    "    padding = np.array([image_box[0] - bounding_box[0], bounding_box[1] - image_box[1]]).clip(0)\n",
    "    bounding_box += padding[0]\n",
    "    padding = np.concatenate((padding.T, np.array([[0, 0]])))\n",
    "    \n",
    "    image = np.pad(image, padding, 'edge')\n",
    "    image = image[slice(*bounding_box[:, 0]), slice(*bounding_box[:, 1])]\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image, label, scale_range=np.zeros(3), translate_range=np.zeros(3)):\n",
    "    image = image.copy()\n",
    "    label = label.copy()\n",
    "    \n",
    "    scale = 1 + (np.random.random(3) - 0.5) * scale_range\n",
    "    translate = (np.random.random(3) - 0.5) * translate_range\n",
    "    \n",
    "    bounds = np.array([[0, 0], [1, 1]], dtype='float')\n",
    "    bounds -= 0.5\n",
    "    bounds *= image.shape[:-1]\n",
    "    bounds /= scale[:-1]\n",
    "    bounds += 64\n",
    "    bounds -= translate[:-1]\n",
    "    bounds = bounds.astype(int)\n",
    "    \n",
    "    image, label = clip(image, label, bounds)\n",
    "    image[image != 1] /= scale[-1]\n",
    "    image[image != 1] += translate[-1]\n",
    "    label[2::3] /= scale[-1]\n",
    "    label[2::3] += translate[-1]\n",
    "    image = np.clip(image, -1, 1)\n",
    "    \n",
    "    image, label = resize(image, label, (128, 128))\n",
    "    image = np.expand_dims(image, 2)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_batch(image_batch, label_batch, scale_range=np.zeros(3), translate_range=np.zeros(3)):\n",
    "    image_batch, label_batch = zip(*[augment(image, label, scale_range, translate_range) \\\n",
    "                                     for image, label in zip(image_batch, label_batch)])\n",
    "    \n",
    "    return np.array(image_batch), np.array(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batches(images, labels, batch_size):\n",
    "    while True:\n",
    "        batch_indices = [(i, min(i + batch_size, len(labels))) for i in range(0, len(labels), batch_size)]\n",
    "        random.shuffle(batch_indices)\n",
    "        for start, end in batch_indices:\n",
    "            image_batch, label_batch = images[start:end], labels[start:end]\n",
    "            yield image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network layers\n",
    "\n",
    "This network is very similar to that implemented in the [Deep Hand Pose](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/oberweger-pca.prototxt) project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Convolution2D(\n",
    "            nb_filter   = 12,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "            subsample   = (2, 2),\n",
    "            input_shape = (128, 128, 1)\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Convolution2D(\n",
    "            nb_filter   = 12,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "            subsample   = (2, 2),\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Convolution2D(\n",
    "            nb_filter   = 12,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(\n",
    "            output_dim  = 1024,\n",
    "            activation  = 'relu'\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 1024,\n",
    "            activation  = 'relu'\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 30,\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 42,\n",
    "            weights     = (pca_eigenvectors, pca_mean),\n",
    "            trainable   = False\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "We use the Adam optimizer, which adaptively modifies the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(),\n",
    "    loss      = 'mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = generate_batches(train_images, train_labels, 64)\n",
    "test_data  = generate_batches(test_images, test_labels, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmented_train_data = (augment_batch(image_batch, label_batch, (0.2, 0.2, 0.2), (32, 32, 0.6)) \\\n",
    "                        for image_batch, label_batch in train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    augmented_train_data,\n",
    "    validation_data   = test_data,\n",
    "    samples_per_epoch = len(train_labels),\n",
    "    nb_val_samples    = len(test_labels),\n",
    "    nb_epoch          = 40000,\n",
    "    callbacks         = [\n",
    "        TensorBoard(),\n",
    "        ModelCheckpoint(\n",
    "            filepath       = 'model.hdf5',\n",
    "            save_best_only = True\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We evaluate the model on the training set with a batch size of 64, measuring the Euclidean loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    batch_size = 64\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
