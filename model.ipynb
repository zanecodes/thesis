{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "This file contains all the code necessary to build  and train the first stage pose estimation model as described in Figure 1b of [Hands Deep in Deep Learning](https://arxiv.org/pdf/1502.06807v2.pdf), but does not yet implement the hand pose prior constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_yaml, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import math\n",
    "import random\n",
    "import h5py\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "\n",
    "The default dataset location is the dataset/ subfolder of the project root.\n",
    "The [.hdf5](http://www.h5py.org/) file produced by [data.ipynb](data#Output-dataset) is placed in this directory after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET_DIR      = 'dataset'\n",
    "dataset          = h5py.File(path.join(DATASET_DIR, 'dataset.hdf5'))\n",
    "\n",
    "test_images      = dataset['image/test']\n",
    "test_labels      = dataset['label/test']\n",
    "test_centers     = dataset['center/test']\n",
    "\n",
    "train_images     = dataset['image/train']\n",
    "train_labels     = dataset['label/train']\n",
    "train_centers    = dataset['center/train']\n",
    "\n",
    "pca_eigenvectors = dataset['pca/eigenvectors'][:30]\n",
    "pca_mean         = dataset['pca/mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resize an image to the specified dimensions, scaling its label accordingly\n",
    "def resize(image, label, dimensions):\n",
    "    scale        = np.array(dimensions) / image.shape[:-1]\n",
    "    label[::3]  *= scale[1]\n",
    "    label[1::3] *= scale[0]\n",
    "    \n",
    "    # TODO: Try to implement or use OpenCV's INTER_AREA resize strategy?\n",
    "    image = scipy.misc.imresize(np.squeeze(image), dimensions, 'bilinear', mode='F')\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clip an image to the specified bounding box, translating its label accordingly\n",
    "# Bounding box should look like np.array([[x_1, y_1], [x_2, y_2]]), where\n",
    "# (x_1, y_1) are the coordinates of the lower left corner and \n",
    "# (x_2, y_2) are the coordinates of the upper right corner\n",
    "def clip(image, label, bounding_box):\n",
    "    label[::3]  -= bounding_box[0, 1]\n",
    "    label[1::3] -= bounding_box[0, 0]\n",
    "    \n",
    "    image_box = np.array([[0, 0], image.shape[:-1]], dtype='int')\n",
    "    \n",
    "    padding = np.array([image_box[0] - bounding_box[0], bounding_box[1] - image_box[1]]).clip(0)\n",
    "    bounding_box += padding[0]\n",
    "    padding = np.concatenate((padding.T, np.array([[0, 0]])))\n",
    "    \n",
    "    image = np.pad(image, padding, 'edge')\n",
    "    image = image[slice(*bounding_box[:, 0]), slice(*bounding_box[:, 1])]\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image, label, scale_range=np.zeros(3), translate_range=np.zeros(3)):\n",
    "    image = image.copy()\n",
    "    label = label.copy()\n",
    "    \n",
    "    scale = 1 + (np.random.random(3) - 0.5) * scale_range\n",
    "    translate = (np.random.random(3) - 0.5) * translate_range\n",
    "    \n",
    "    bounds = np.array([[0, 0], [1, 1]], dtype='float')\n",
    "    bounds -= 0.5\n",
    "    bounds *= image.shape[:-1]\n",
    "    bounds /= scale[:-1]\n",
    "    bounds += 64\n",
    "    bounds -= translate[:-1]\n",
    "    bounds = bounds.astype(int)\n",
    "    \n",
    "    image, label = clip(image, label, bounds)\n",
    "    image[image != 1] /= scale[-1]\n",
    "    image[image != 1] += translate[-1]\n",
    "    label[2::3] /= scale[-1]\n",
    "    label[2::3] += translate[-1]\n",
    "    image = np.clip(image, -1, 1)\n",
    "    \n",
    "    image, label = resize(image, label, (128, 128))\n",
    "    image = np.expand_dims(image, 2)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_batch(image_batch, label_batch, scale_range=np.zeros(3), translate_range=np.zeros(3)):\n",
    "    image_batch, label_batch = zip(*[augment(image, label, scale_range, translate_range) \\\n",
    "                                     for image, label in zip(image_batch, label_batch)])\n",
    "    \n",
    "    return np.array(image_batch), np.array(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batches(images, labels, batch_size):\n",
    "    while True:\n",
    "        batch_indices = [(i, min(i + batch_size, len(labels))) for i in range(0, len(labels), batch_size)]\n",
    "        random.shuffle(batch_indices)\n",
    "        for start, end in batch_indices:\n",
    "            image_batch, label_batch = images[start:end], labels[start:end]\n",
    "            yield image_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "The loss function used in the [Deep Hand Pose](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/oberweger-bgn.prototxt#L574) project is [Caffe's Euclidean loss](http://caffe.berkeleyvision.org/tutorial/layers/euclideanloss.html), which is computed as\n",
    "\n",
    "$$ \\frac 1 {2N} \\sum_{i=1}^N \\| {x_1}_i - {x_2}_i \\|^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean(y_true, y_pred):\n",
    "    n = int(y_pred.get_shape()[1])\n",
    "    return tf.reduce_sum((y_true - y_pred) ** 2) / (2 * n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate decay policy\n",
    "\n",
    "The learning rate decay policy used in [Deep Hand Pose](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/solver.prototxt#L24) is [Caffe's 'inv' policy](https://github.com/jsupancic/deep_hand_pose/blob/master/src/caffe/proto/caffe.proto#L162), where the current learning rate is defined to be\n",
    "\n",
    "$$ r(i) = \\frac {r(0)} {(1 + \\gamma i) ^ p} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inv_decay(base_lr, gamma, power):\n",
    "    def decay(epoch):\n",
    "        return base_lr * (1 + gamma * epoch) ** (-power)\n",
    "    \n",
    "    return decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier initializer\n",
    "\n",
    "The convolutional layers in the [Deep Hand Pose](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/oberweger-pca.prototxt#L53) project use [Caffe's Xavier filler](http://caffe.berkeleyvision.org/doxygen/classcaffe_1_1XavierFiller.html#details), which is computed as\n",
    "\n",
    "$$ x \\sim U(-a, +a) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ a = \\sqrt {\\frac 3 n} $$\n",
    "\n",
    "and $ n $, by default, is the number of inputs to the layer (fan in).\n",
    "\n",
    "Keras has a similar [he_uniform](https://github.com/fchollet/keras/blob/master/keras/initializations.py#L80) initializer, where\n",
    "\n",
    "$$ a = \\sqrt {\\frac 6 n} $$\n",
    "\n",
    "and $ n $ is the number of inputs to the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xavier(shape, name=None, dim_ordering='th'):\n",
    "    fan_in, fan_out = initializations.get_fans(shape, dim_ordering=dim_ordering)\n",
    "    s = np.sqrt(3. / fan_in)\n",
    "    return initializations.uniform(shape, s, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian initializer\n",
    "\n",
    "The fully connected layers in the [Deep Hand Pose](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/oberweger-pca.prototxt#L195) project use [Caffe's Gaussian filler](http://caffe.berkeleyvision.org/doxygen/classcaffe_1_1GaussianFiller.html#details) with various standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(std_dev):\n",
    "    def init(shape, name=None):\n",
    "        return initializations.normal(shape, std_dev, name)\n",
    "    \n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network layers\n",
    "\n",
    "This network is very similar to that implemented in the [Deep Hand Pose](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/oberweger-pca.prototxt) project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Convolution2D(\n",
    "            nb_filter   = 8,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "            init        = xavier,\n",
    "            input_shape = (128, 128, 1)\n",
    "        ),\n",
    "        MaxPooling2D(\n",
    "            pool_size   = (2, 2)\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Convolution2D(\n",
    "            nb_filter   = 8,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "            init        = xavier\n",
    "        ),\n",
    "        MaxPooling2D(\n",
    "            pool_size   = (2, 2)\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Convolution2D(\n",
    "            nb_filter   = 8,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "            init        = xavier\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(\n",
    "            output_dim  = 1024,\n",
    "            init        = gaussian(std_dev=0.01),\n",
    "            activation  = 'relu'\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 1024,\n",
    "            init        = gaussian(std_dev=0.05),\n",
    "            activation  = 'relu'\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 30,\n",
    "            init        = gaussian(std_dev=0.02)\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 42,\n",
    "            weights     = (pca_eigenvectors, pca_mean),\n",
    "            trainable   = False\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "The optimizer used in the [Deep Hand Pose](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/solver.prototxt#L37) project is [Caffe's stochastic gradient descent](http://caffe.berkeleyvision.org/tutorial/solver.html#sgd), with an [initial learning rate](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/solver.prototxt#L17) of 0.000005 and a [momentum](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/solver.prototxt#L19) of 0.9.\n",
    "\n",
    "As mentioned [above](#Loss-function), the loss function used is Euclidean loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(),\n",
    "    loss      = 'mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Similarly to the Deep Hand Pose project, we perform [40000 epochs](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/solver.prototxt#L31) of training with batches of [64 images](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/oberweger-pca.prototxt#L14).\n",
    "\n",
    "As mentioned [above](#Learning-rate-decay-policy), the learning rate decay used is Caffe's 'inv' policy, with an [initial learning rate](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/solver.prototxt#L17) of 0.000005, a [gamma](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/solver.prototxt#L25) of 0.0001, and a [power](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/solver.prototxt#L26) of 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = generate_batches(train_images, train_labels, 64)\n",
    "test_data  = generate_batches(test_images, test_labels, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmented_train_data = (augment_batch(image_batch, label_batch, (0.2, 0.2, 0.2), (32, 32, 0.6)) \\\n",
    "                        for image_batch, label_batch in train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    augmented_train_data,\n",
    "    validation_data   = test_data,\n",
    "    samples_per_epoch = len(train_labels),\n",
    "    nb_val_samples    = len(test_labels),\n",
    "    nb_epoch          = 40000,\n",
    "    callbacks         = [\n",
    "        TensorBoard(),\n",
    "        ModelCheckpoint(\n",
    "            filepath       = 'model.hdf5',\n",
    "            save_best_only = True\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We evaluate the model on the training set with a batch size of 64, measuring the Euclidean loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    batch_size = 64\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
