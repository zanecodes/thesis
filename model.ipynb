{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "This file contains all the code necessary to build  and train the first stage pose estimation model as described in Figure 1b of [Hands Deep in Deep Learning](https://arxiv.org/pdf/1502.06807v2.pdf), but does not yet implement the hand pose prior constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_yaml, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import math\n",
    "import random\n",
    "import h5py\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "\n",
    "The default dataset location is the dataset/ subfolder of the project root.\n",
    "The [.hdf5](http://www.h5py.org/) file produced by [data.ipynb](data#Output-dataset) is placed in this directory after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET_DIR      = 'dataset'\n",
    "dataset          = h5py.File(path.join(DATASET_DIR, 'dataset.hdf5'))\n",
    "\n",
    "test_images      = dataset['image/test']\n",
    "test_labels      = dataset['label/test']\n",
    "test_centers     = dataset['center/test']\n",
    "\n",
    "train_images     = dataset['image/train']\n",
    "train_labels     = dataset['label/train']\n",
    "train_centers    = dataset['center/train']\n",
    "\n",
    "pca_eigenvectors = dataset['pca/eigenvectors'][:30]\n",
    "pca_mean         = dataset['pca/mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resize an image to the specified dimensions, scaling its label accordingly\n",
    "def resize(image, label, dimensions):\n",
    "    scale        = np.array(dimensions) / image.shape[:-1]\n",
    "    label[::3]  *= scale[1]\n",
    "    label[1::3] *= scale[0]\n",
    "    \n",
    "    # TODO: Try to implement or use OpenCV's INTER_AREA resize strategy?\n",
    "    image = scipy.misc.imresize(np.squeeze(image), dimensions, 'bilinear', mode='F')\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clip an image to the specified bounding box, translating its label accordingly\n",
    "# Bounding box should look like np.array([[x_1, y_1], [x_2, y_2]]), where\n",
    "# (x_1, y_1) are the coordinates of the lower left corner and \n",
    "# (x_2, y_2) are the coordinates of the upper right corner\n",
    "def clip(image, label, bounding_box):\n",
    "    label[::3]  -= bounding_box[0, 1]\n",
    "    label[1::3] -= bounding_box[0, 0]\n",
    "    \n",
    "    image_box = np.array([[0, 0], image.shape[:-1]], dtype='int')\n",
    "    \n",
    "    padding = np.array([image_box[0] - bounding_box[0], bounding_box[1] - image_box[1]]).clip(0)\n",
    "    bounding_box += padding[0]\n",
    "    padding = np.concatenate((padding.T, np.array([[0, 0]])))\n",
    "    \n",
    "    image = np.pad(image, padding, 'edge')\n",
    "    image = image[slice(*bounding_box[:, 0]), slice(*bounding_box[:, 1])]\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image, label, scale_range=np.zeros(3), translate_range=np.zeros(3)):\n",
    "    image = image.copy()\n",
    "    label = label.copy()\n",
    "    \n",
    "    scale = 1 + (np.random.random(3) - 0.5) * scale_range\n",
    "    translate = (np.random.random(3) - 0.5) * translate_range\n",
    "    \n",
    "    bounds = np.array([[0, 0], [1, 1]], dtype='float')\n",
    "    bounds -= 0.5\n",
    "    bounds *= image.shape[:-1]\n",
    "    bounds /= scale[:-1]\n",
    "    bounds += 64\n",
    "    bounds -= translate[:-1]\n",
    "    bounds = bounds.astype(int)\n",
    "    \n",
    "    image, label = clip(image, label, bounds)\n",
    "    image[image != 1] /= scale[-1]\n",
    "    image[image != 1] += translate[-1]\n",
    "    label[2::3] /= scale[-1]\n",
    "    label[2::3] += translate[-1]\n",
    "    image = np.clip(image, -1, 1)\n",
    "    \n",
    "    image, label = resize(image, label, (128, 128))\n",
    "    image = np.expand_dims(image, 2)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_batch(image_batch, label_batch, scale_range=np.zeros(3), translate_range=np.zeros(3)):\n",
    "    image_batch, label_batch = zip(*[augment(image, label, scale_range, translate_range) \\\n",
    "                                     for image, label in zip(image_batch, label_batch)])\n",
    "    \n",
    "    return np.array(image_batch), np.array(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batches(images, labels, batch_size):\n",
    "    while True:\n",
    "        batch_indices = [(i, min(i + batch_size, len(labels))) for i in range(0, len(labels), batch_size)]\n",
    "        random.shuffle(batch_indices)\n",
    "        for start, end in batch_indices:\n",
    "            image_batch, label_batch = images[start:end], labels[start:end]\n",
    "            yield image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network layers\n",
    "\n",
    "This network is very similar to that implemented in the [Deep Hand Pose](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/oberweger-pca.prototxt) project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Convolution2D(\n",
    "            nb_filter   = 12,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "            subsample   = (2, 2),\n",
    "            input_shape = (128, 128, 1)\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Convolution2D(\n",
    "            nb_filter   = 12,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "            subsample   = (2, 2),\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Convolution2D(\n",
    "            nb_filter   = 12,\n",
    "            nb_row      = 5,\n",
    "            nb_col      = 5,\n",
    "        ),\n",
    "        LeakyReLU(\n",
    "            alpha       = 0.05\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(\n",
    "            output_dim  = 1024,\n",
    "            activation  = 'relu'\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 1024,\n",
    "            activation  = 'relu'\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 30,\n",
    "        ),\n",
    "        Dense(\n",
    "            output_dim  = 42,\n",
    "            weights     = (pca_eigenvectors, pca_mean),\n",
    "            trainable   = False\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "We use the Adam optimizer, which adaptively modifies the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(),\n",
    "    loss      = 'mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = generate_batches(train_images, train_labels, 64)\n",
    "test_data  = generate_batches(test_images, test_labels, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmented_train_data = (augment_batch(image_batch, label_batch, (0.2, 0.2, 0.2), (32, 32, 0.6)) \\\n",
    "                        for image_batch, label_batch in train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Similarly to the Deep Hand Pose project, we train on batches of [64 images and labels](https://github.com/jsupancic/deep_hand_pose/blob/master/examples/deep_hand_pose/oberweger-pca.prototxt#L14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    augmented_train_data,\n",
    "    validation_data   = test_data,\n",
    "    samples_per_epoch = len(train_labels),\n",
    "    nb_val_samples    = len(test_labels),\n",
    "    nb_epoch          = 100,\n",
    "    callbacks         = [\n",
    "        TensorBoard(),\n",
    "        ModelCheckpoint(\n",
    "            filepath       = 'model.hdf5',\n",
    "            save_best_only = True\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We evaluate the model on the training set with a batch size of 64, measuring the Euclidean loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    batch_size = 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    test_images,\n",
    "    batch_size = 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uvd_to_xyz(uvd):\n",
    "    normalized_x = uvd[..., 0] / 640 - 0.5\n",
    "    normalized_y = 0.5 - uvd[..., 1] / 480\n",
    "    \n",
    "    xyz = np.zeros(uvd.shape)\n",
    "    xyz[..., 2] = uvd[..., 2]\n",
    "    xyz[..., 0] = normalized_x * xyz[..., 2] * 1.08836710\n",
    "    xyz[..., 1] = normalized_y * xyz[..., 2] * 0.817612648\n",
    "    \n",
    "    return xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize(label, center):\n",
    "    label = label.copy()\n",
    "    \n",
    "    bounds = np.array([[0, 0], [1, 1]], dtype='float')\n",
    "    bounds = bounds[None, ...].repeat(len(label), 0)\n",
    "    bounds -= 0.5\n",
    "    bounds *= 38\n",
    "    bounds *= 525 / center[..., -1, None, None]\n",
    "    bounds += center[..., None, -2::-1]\n",
    "    bounds = bounds.astype(int)\n",
    "    \n",
    "    label[..., 0:2] /= (128, 128) / (bounds[..., None, 1, :] - bounds[..., None, 0, :])\n",
    "    label[..., -1] *= 15.0\n",
    "    label[..., -1] += center[..., -1, None]\n",
    "    \n",
    "    label[..., 0:2] += bounds[..., None, 0, :]\n",
    "    \n",
    "    label[..., -1] *= 10\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold(actual, predicted, threshold):\n",
    "    max_distance = np.sqrt(np.sum((actual - predicted) ** 2, -1)).max(-1)\n",
    "    count = np.sum((max_distance[..., None] < threshold), axis=0)\n",
    "    return count / len(max_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = threshold(\n",
    "    uvd_to_xyz(denormalize(test_labels[:].reshape(-1, 14, 3), test_centers[:])),\n",
    "    uvd_to_xyz(denormalize(predictions.reshape(-1, 14, 3), test_centers[:])),\n",
    "    np.linspace(0, 80, 1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd2b7df320>]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noIuIlAgVdBGREqGCLiJSIlTQRURKxP8BDAVm/JU/jZEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd2b854240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.yticks(np.arange(0, 100, 20))\n",
    "plt.grid()\n",
    "plt.plot(np.linspace(0, 80, 1000), error * 100)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
